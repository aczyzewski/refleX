{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJwLLyDJw5w-"
   },
   "source": [
    "### Generator wykresów \n",
    "\n",
    "#### Generator opiera się na 4 pętlach for. Pętle bazują kolejno na: klasyfikatorach, cechach, metodach liczenia wyniku, statystykach. Do stworzenia jednego wykresu potrzeba wszystkich statystyk - czyli pełnego obiegu pętli 4-tej. W funkcji initDF trzeba wpisać ścieżkę z której pobierane są zdjęcia ( aktualnie jest to ustawione tak jak Faustyna dodała wektory 1d (każdy rodzaj jest w innym folderze)). Hierarchia:\n",
    "\n",
    "###### 1dNew\n",
    "######  ---------5th_percentile \n",
    "###### ------------------------------ 1d vectors\n",
    "###### ---------median \n",
    "######  -------------------------------1d vectors \n",
    "###### etc.\n",
    "\n",
    "#### Do przemyślenia są zmienne globalne które zmienie, ale narazie nie mam pomysłu jak to inaczej rozwiązać. Wykresy tworzą się bezpośrednio w folderze w którym jest wklejony plik jupytera.\n",
    "\n",
    "#### Klasyfikatory mają wpisane opytmalne wartości policzone dzięki  Grid & Random Serach (choć nie wsyzstkie nad czym pracuje) - być może połączę liczenie optymalnych wartości dla klasyfikatorów wraz z poniższą częścią, choć nie wiem czy jest sens - po ustaleniu, że np. RandomForest najlepiej działa dla no_estimatorsimators = 70, to średnio jest sens znowu to udowadniać. \n",
    "\n",
    "#### Mój angielski jest średni ale specjalnie pisałem komentarze niepolskie bo cza kiedyś zacząć. Jak coś jest po chińsku, a nie po ang to po konsultacji autor może powiedzieć co miał na myśli. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ouIJ_V_U2rZv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import glob \n",
    "import sys\n",
    "#import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Lr5IN4B8qAJ9"
   },
   "outputs": [],
   "source": [
    "#@title Classifier Parameters\n",
    "\n",
    "result_plot_dir = \"/home/reflex/reflex/result_plots/\" #@param {type:\"string\"}\n",
    "joint_csv_path = '/home/reflex/reflex/joint_file.csv' #@param {type:\"string\"}\n",
    "no_estimators = 70 #@param {type:\"raw\"}\n",
    "no_cv_folds = 10 #@param {type:\"raw\"}\n",
    "no_jobs = 8 #@param {type:\"raw\"}\n",
    "no_neighbours = 3 #@param {type:\"raw\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bTJ749kqn2Q4"
   },
   "source": [
    "## Global variables and constatnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UDYzwIof2wpu"
   },
   "outputs": [],
   "source": [
    "statistics = [\"min\" , \"max\", \"var\", \"median\", \"mean\",\"95th_percentile\",\"5th_percentile\"]\n",
    "scoring_types = ['recall_macro','accuracy','precision','recall','f1','roc_auc']\n",
    "class_names = [\"Loop scattering\",\"Background ring\",\"Strong background\",\"Diffuse scattering\",\"Artifact\",\"Ice ring\",\"Non-uniform detector\"]\n",
    "classifier_names = [\"RFC\",\"DTC\",\"KNN\",\"GaussianNB\",\"QuadraticDisciminantAnalysis\", \"GPC\", \"SVC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "I15r8d02s0qn"
   },
   "outputs": [],
   "source": [
    "def get_classifier_filename(classifier_name, class_name):\n",
    "  \n",
    "    if classifier_name not in classifier_names:\n",
    "      raise Exception(\"Invalid classifier name!\")\n",
    "  \n",
    "    return dict(zip(classifier_names, [\n",
    "      result_plot_dir + \"RFClf-cv\"+str(no_cv_folds)+\"-n_est\"+str(no_estimators)+\"-\"+class_name+\".jpg\",\n",
    "      result_plot_dir + \"DTClf-cv\"+str(no_cv_folds)+class_name+\".jpg\",\n",
    "      result_plot_dir + \"KNNClf-cv\"+str(no_cv_folds)+\"-neighbours-\"+str(no_neighbours)+\"-\"+class_name+\".jpg\",\n",
    "      result_plot_dir + \"GaussClf-cv\"+str(no_cv_folds)+\"-\"+class_name+\".jpg\",\n",
    "      result_plot_dir + \"QDAClf-cv\"+str(no_cv_folds)+\"-\"+class_name+\".jpg\",\n",
    "      result_plot_dir + \"GaussPrc-cv\"+str(no_cv_folds)+\"-\"+class_name+\".jpg\",\n",
    "      result_plot_dir + \"SV-cv\"+str(no_cv_folds)+\"-\"+class_name+\".jpg\" \n",
    "    ]))[classifier_name]\n",
    "    \n",
    "\n",
    "'''\n",
    "Constructs an appropriate classifier object for the given classifier name.\n",
    "'''\n",
    "def get_classifier(classifier_name):\n",
    "  \n",
    "    if classifier_name not in classifier_names:\n",
    "      raise Exception(\"Invalid classifier name!\")\n",
    "    \n",
    "    classifier_objects = [\n",
    "        RandomForestClassifier(random_state=23, n_estimators=no_estimators, n_jobs=no_jobs),\n",
    "        DecisionTreeClassifier(random_state=10),\n",
    "        KNeighborsClassifier(n_neighbors=no_neighbors, n_jobs=no_jobs),\n",
    "        GaussianNB(),\n",
    "        QuadraticDiscriminantAnalysis(),\n",
    "        GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "        SVC(gamma=2, C=1, probability=\"True\")\n",
    "    ]\n",
    "        \n",
    "    return dict(zip(classifier_names, classifier_objects))[classifier_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eJNR3_RdHOOS"
   },
   "outputs": [],
   "source": [
    "def create_joint_vector(image, directory, statistics=None, all_statistics=False, sort=False, \n",
    "                        sort_function=lambda x: x, vector_length=None, \n",
    "                        fill_value=None, image_as_index=True, predefined_file_list=None, \n",
    "                        remove_suffix=False):\n",
    "\n",
    "  \"\"\"\n",
    "  Tworzy dataframe z wybranego zdjecia w postaci <nazwa_zdjecia> <wektor_zlaczonych_statystyk>\n",
    "  \n",
    "  Params:\n",
    "  --------------\n",
    "    image                 - nazwa pliku ze zdjeciem (z suffixem (.SSSxSSS.png))\n",
    "    directory             - katalog z katalogami ze wszystkimi statystykami\n",
    "    statistics            - lista statystyk branych pod uwage\n",
    "    all_statistics        - jezeli True to poprzedni parametr jest ignorowany i pod uwage bierzemy\n",
    "                            wszystkie statystyki we wskazanym folderze\n",
    "    sort                  - jezeli True to nazwy statystyk sortowane sa wedlug podanej funkcji\n",
    "                            sortujacej (domyslnie leksykograficznie)\n",
    "    sort_function         - funkcja (key) sortujaca statystyki (domyslnie leksykograficznie)\n",
    "    vector_length         - parametr okreslajacy pozadana dlugosc wektora. W przypadku \n",
    "                            nadmiaru jest przycinany, w przeciwnym razie jest wypelniniany\n",
    "                            kolejnym paremetrem. Niezdefiniowany (None) nie modyfikuje wektora.\n",
    "    fill_value            - wartosc, ktora wypelniany bedzie wektor, jezeli będzie za krótki\n",
    "                            w przypadku zdefiniowania dlugości\n",
    "    image_as_index        - ustawie nazwe pliku jako index DataFrame'u\n",
    "    remove_suffix         - usuwa suffix (.SSSxSSS.png) z nazwy pliku\n",
    "    \n",
    "                     \n",
    "   Returns:\n",
    "   --------------\n",
    "    None                  - w przpadku bledu (brak zdef. statystyk, zly katalog, zla nazwa pliku)\n",
    "    Dataframe             - kiedy wszystko poszlo zgodnie z zalozeniami\n",
    "                    \n",
    "                      \n",
    "  \"\"\"\n",
    "  \n",
    "  # Normalizacja sciezki do foldery\n",
    "  if directory[-1] != '/':\n",
    "    directory += '/'\n",
    "    \n",
    "  # Sprawdzamy czy mamy jakiekolwiek statystyki do złączenia\n",
    "  statistic_names = list(os.listdir(directory)) if all_statistics else statistics \n",
    "\n",
    "  if statistic_names:   \n",
    "\n",
    "    # Aby uniknąć niedeterminizumu (?) w przypadku listdir sortujemy sortujemy statystyki leksykograficznie\n",
    "    if sort:\n",
    "      statistic_names.sort(key=sort_function)\n",
    "\n",
    "    values = []\n",
    "\n",
    "    # Laczenie wektora\n",
    "    for stat_name in statistic_names:\n",
    "\n",
    "      current_vector = cv.imread(f'{directory}{stat_name}/{image}', cv.IMREAD_GRAYSCALE).flatten().tolist()\n",
    "      \n",
    "      # Dostosowywanie dlugosci wektora\n",
    "      if vector_length:\n",
    "        current_vector = current_vector[:vector_length]\n",
    "        current_vector.extend([fill_value] * max(0, vector_length - len(current_vector)))\n",
    "      \n",
    "      values.append(current_vector)\n",
    "\n",
    "    # Tworzenie dataframe\n",
    "    \n",
    "    if remove_suffix:\n",
    "      image = image[:-12]\n",
    "      \n",
    "    data = []\n",
    "    column_names = ['img']\n",
    "    for idx, stat_vec in enumerate(values):\n",
    "      column_names += [f'{statistic_names[idx]}_{i}' for i in range(len(stat_vec))]\n",
    "      data += stat_vec\n",
    "      \n",
    "    df = pd.DataFrame([[image, *data]], columns=column_names)\n",
    "\n",
    "    # Ustawianie nowego indexu\n",
    "    if image_as_index:\n",
    "      df.set_index('img', inplace=True)\n",
    "\n",
    "    return df\n",
    "      \n",
    "  return None\n",
    "\n",
    "\n",
    "'''\n",
    "Constructs a DataFrame from all vector files in the given directory.\n",
    "'''\n",
    "def vector_folder_to_df(directory, limit=None):\n",
    "  \n",
    "  files = list(os.listdir(directory + '/' + list(os.listdir(directory))[0]))\n",
    "  all_dfs = []\n",
    "\n",
    "  for idx, image in enumerate(files[:limit]): \n",
    "    all_dfs.append(create_joint_vector(image, directory, all_statistics=True, sort=True, vector_length=240, remove_suffix=True, image_as_index=True))\n",
    "    \n",
    "  return pd.concat(all_dfs)\n",
    "\n",
    "\n",
    "def extract_filename(path):\n",
    "    path, filename = os.path.split(path)\n",
    "    return '.'.join(filename.split('.')[:-1])\n",
    "\n",
    "  \n",
    "def construct_joint_csv(output_filepath):\n",
    "  \n",
    "  df1 = pd.read_csv('/home/reflex/reflex/data/results_constant_vector_length/vectors/vectors.csv')\n",
    "  df1.set_index('img', inplace=True, drop=True)\n",
    "  \n",
    "  df2 = pd.read_csv('/home/reflex/reflex/reflex.csv')\n",
    "  df2['Image'] = df2['Image'].apply(lambda x: extract_filename(x))\n",
    "  df2.set_index('Image', inplace=True, drop=True)\n",
    "\n",
    "  joint = pd.concat([df1, df2], axis=1, join='inner')\n",
    "  joint.to_csv(output_filepath)\n",
    "  return joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Dz6hoJLygC0e"
   },
   "outputs": [],
   "source": [
    "def classify(X, y, classifier_name, scoring):    \n",
    "  \n",
    "    # TODO now clf automaticly divide into train/test set, but most of clfs takes divided sets\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.1, random_state=42)\n",
    "    #print(f'Training set size: {len(X_train)} & Test set size: {len(X_test)}')\n",
    "    ### cv - cross-validation generator - default KFold(n_splits, shuffle, random state) splits into K folds \n",
    "    ### it trains on K-1, test on 'untouched' 1 part\n",
    "    \n",
    "    clf = get_classifier(classifier_name)\n",
    "    return cross_val_score(clf, X, y, cv=no_cv_folds, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_eG-D6EWoiDP"
   },
   "outputs": [],
   "source": [
    "def plot(data, classifier_name, class_name, scoring_names):    \n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12,12))\n",
    "    ax1.set_title(f'{class_name}-{classifier_name}-{no_cv_folds}folds')\n",
    "    \n",
    "    x = []\n",
    "    for i in range(len(data)):\n",
    "      for j in range(len(data[0])):\n",
    "        x.append(i+1)\n",
    "    y = np.array(data).flatten()\n",
    "\n",
    "    color = np.tile(np.arange(len(data[0])), len(scoring_names))\n",
    "    scatter = ax1.scatter(x, y, s=20, c=color)\n",
    "    cbar = plt.colorbar(scatter, ax=[ax1, ax2])\n",
    "    cbar.set_ticks(np.arange(len(data[0])))\n",
    "    \n",
    "    ax2.boxplot(data, 0, 'gD', 1)\n",
    "    \n",
    "    ax2.set_xticklabels(scoring_names, rotation=45)\n",
    "        \n",
    "    plt.show()\n",
    "    f.savefig(get_classifier_filename(classifier_name, class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Vx1Af01som1a"
   },
   "outputs": [],
   "source": [
    "def initDF(class_name):\n",
    "        \n",
    "    joined = pd.read_csv(joint_csv_path)\n",
    "    print(\"Dataset size: \", len(joined))\n",
    "    \n",
    "    y = joined.loc[:, class_name].values\n",
    "    X = joined.as_matrix(columns=joined.columns[1:-7])\n",
    "    \n",
    "    return X, y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ci2CgUgCx_s5"
   },
   "outputs": [],
   "source": [
    "def initDF_augmented(class_name):\n",
    "        \n",
    "    joined = pd.read_csv(joint_csv_path)\n",
    "    print(\"Dataset size: \", len(joined))\n",
    "    \n",
    "    \n",
    "    for index, row in joined.iterrows():\n",
    "      print(index)\n",
    "      print(row)\n",
    "    \n",
    "    y = joined.loc[:, class_name].values\n",
    "    X = joined.as_matrix(columns=joined.columns[1:-7])\n",
    "    \n",
    "    return X, y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-LR7ZH4dw5w_"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "      \n",
    "    for classifier_name in classifier_names: # iterate over classifiers (RFC,DTC ...)\n",
    "        print(\"Classifier:\", classifier_name)  \n",
    "        \n",
    "        for class_name in class_names:  # iterate over classes (Strong Bg, Loop Scattering, ... ) \n",
    "            print(class_name, end=' ')\n",
    "            #X, y = initDF(class_name)\n",
    "            X, y = initDF_augmented(class_name)\n",
    "            \n",
    "            scores = []\n",
    "            for scoring in scoring_types[:2]:  # iterate over scoring types (Accuracy, Recall ...)\n",
    "                print('.', end='')\n",
    "                result = classify(X, y, classifier_name, scoring) #FIXME runs classifier to calculate each score\n",
    "                scores.append(result)\n",
    "            \n",
    "            plot(scores, classifier_name, class_name, scoring_types) # plot all stats on specific: CLF , FEATURE , SCORING_TYPE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 861,
     "status": "error",
     "timestamp": 1530867995050,
     "user": {
      "displayName": "Ice Ring",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103968338750374102762"
     },
     "user_tz": -120
    },
    "id": "sezWTPAo2-on",
    "outputId": "c3aaa395-77c8-4165-9178-4eccb481c40c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RFC\n",
      "Loop scattering "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-342-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-340-a43b4ad6e321>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m#X, y = initDF(class_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitDF_augmented\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-339-bab97c3ab716>\u001b[0m in \u001b[0;36minitDF_augmented\u001b[0;34m(class_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minitDF_augmented\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mjoined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoint_csv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset size: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1067\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m     \"\"\"\n\u001b[1;32m    779\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#construct_joint_csv(joint_csv_path)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "25CHWXwugcaC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "ClassificationTry.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
